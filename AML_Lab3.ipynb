{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AML_Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SMM2RQWYh-0"
      },
      "source": [
        "### Week 3: Reccurent Neural Networks\n",
        "```\n",
        "- Advanced Machine Learning, Innopolis University \n",
        "- Professor: Muhammad Fahim \n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "```\n",
        "<hr>\n",
        "\n",
        "\n",
        "```\n",
        "Lab Plan\n",
        "1. Movie Sentiment Analysis\n",
        "    a. Dataset\n",
        "    b. Data Preprocessing\n",
        "    c. PyTorch RNN \n",
        "    d. Keras Simple Neural Network \n",
        "    e. Keras Convolutional Neural Network\n",
        "    f. Lab Task\n",
        "```\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edS-8CFYcAe"
      },
      "source": [
        "## Dataset Description\n",
        "\n",
        "[IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/) having 50K movie reviews for **natural language processing** or **Text analytics.** This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX8Y56qHYcAl"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "[`torchtext`](https://pytorch.org/text/stable/index.html) is a package that consists of data processing utilities and popular datasets for natural language\n",
        "\n",
        "One of the main concepts of TorchText is the `Field`. To define how the data should be processed we will use `Field`. Our input data contains raw strings <br>\n",
        "The declared `TEXT` field defines how the review should be processed, and the `LABEL` field to process the sentiment. \n",
        "\n",
        "For more on `Fields`, go [here](https://github.com/pytorch/text/blob/master/torchtext/data/field.py).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFGKi6vXYcAn"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED) #REPORDUCEABILITY\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Dg1WbbYcAn"
      },
      "source": [
        "## Download the data\n",
        "The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as `torchtext.datasets` objects. It process the data using the `Fields` we have previously defined. The IMDb dataset consists of 50,000 movie reviews, each marked as being a positive or negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhMqmCDkYcAo",
        "outputId": "517b7eec-ebcb-4476-c7bd-2e05468797d9"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL) #Splits half half\n",
        "\n",
        "print(f'{len(train_data)} training examples')\n",
        "print(f'{len(test_data)} testing examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 training examples\n",
            "25000 testing examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w42fi2uaYcAq",
        "outputId": "ac8fa698-b294-4bba-9d3e-1626e2be4592"
      },
      "source": [
        "print(vars(train_data.examples[5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Despite', 'gorgeous', 'and', 'breathtaking', 'animation', ',', 'this', 'is', 'probably', 'one', 'of', 'most', 'uninspiring', 'Disney', 'films', 'I', \"'ve\", 'seen', ',', 'and', 'I', 'do', \"n't\", 'slam', 'Disney', 'films', 'very', 'often', '.', 'Spirit', 'is', 'a', 'wild', 'stallion', 'who', 'repeatedly', 'gets', 'captured', ',', 'either', 'by', 'the', 'cavalry', 'or', 'by', 'Indians', ',', 'both', 'of', 'which', 'try', 'to', '\"', 'break', '\"', 'him', '.', 'Spirit', 'ends', 'up', 'forming', 'a', 'bond', 'with', 'the', 'Indian', ',', 'and', 'that', ',', 'in', 'a', 'nutshell', ',', 'is', 'the', 'story', '.', 'With', 'exception', 'to', 'the', 'beautiful', 'animation', 'of', 'the', 'horses', ',', 'neither', 'I', 'or', 'my', 'five', 'year', 'old', 'were', 'very', 'inspired', 'or', 'excited', 'by', 'this', 'film', '.', 'It', \"'s\", 'ironic', 'that', 'it', \"'s\", 'titled', '\"', 'Spirit', '\"', ',', 'as', 'spirit', 'is', 'what', 'this', 'film', 'could', 'have', 'used', 'a', 'bit', 'more', 'of', '.', 'An', 'extra', 'point', 'was', 'given', 'for', 'the', 'soundtrack', ',', 'which', 'was', 'enjoyable', ',', 'with', 'songs', 'by', 'Bryan', 'Adams', 'and', 'Hans', 'Zimmer', '.', 'And', 'although', 'this', 'film', 'is', 'rated', 'G', ',', 'you', 'will', 'still', 'probably', 'have', 'to', 'end', 'up', 'explaining', 'what', '\"', 'breaking', 'a', 'horse', '\"', 'means', 'to', 'your', 'five', 'year', 'old', '.', 'I', 'did.<br', '/><br', '/', '>'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkUWxRVvYcAr"
      },
      "source": [
        "## Split the data to train and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnkIgmfwYcAr"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfwt62cLYcAr"
      },
      "source": [
        "Again, we'll view how many examples are in each split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33-NKWj7YcAs",
        "outputId": "32836adc-f647-4fa5-bc88-cfb810d1ebb8"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CGxi9kIYcAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643d8e01-e8ed-42b5-83c7-d4d621886cc7"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "# TEXT.build_vocab(train_data, vectors='glove.6B.100d')\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(MAX_VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc3K35fQYcAu"
      },
      "source": [
        "Why do we only build the vocabulary on the training set? When testing any machine learning system you do not want to look at the test set in any way. We do not include the validation set as we want it to reflect the test set as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiirlj6fYcAu",
        "outputId": "e8071e3a-1b00-45ba-97d9-104a3d56662d"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\") #Additional 2 you create them yourself and represented as unknown.\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0EGn7cwYcAw"
      },
      "source": [
        "We can also check the labels, 0 is for negative and 1 is for positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoB8WOCSYcAw",
        "outputId": "1bdf2f87-b71b-47b8-d222-68b2b62cada7"
      },
      "source": [
        "print(LABEL.vocab.stoi)\n",
        "# print(LABEL.vocab) #object"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n",
            "<torchtext.vocab.Vocab object at 0x7f992e42df90>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgjGe4DhYcAx"
      },
      "source": [
        "## Dataloders / Iterators \n",
        "\n",
        "* We have done preprocessing of the raw data but we have to create batches and convert the data to tensors. For text data Pytorch provides a container called `BucketIterator` for such task.\n",
        "\n",
        "* The `BucketIterator` will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
        "\n",
        "* To put the data into the training device, its neccesary to specify the device parameter in the `BucketIterator` then Pytorch will take care of the rest. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZarz-5NYcAx"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data), \n",
        "    batch_size = batch_size,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxH-cBsQYcAx"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "The next stage is building the model that we'll eventually train and evaluate. \n",
        "\n",
        "There is a small amount of boilerplate code when creating models in PyTorch, note how our `RNN` class is a sub-class of `nn.Module` and the use of `super`.\n",
        "\n",
        "Within the `__init__` we define the _layers_ of the module. Our three layers are an _embedding_ layer, our RNN, and a _linear_ layer. All layers have their parameters initialized to random values, unless explicitly specified.\n",
        "\n",
        "\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment7.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKf7tztuYcAz"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  #input_dim: dim of one hot encoding\n",
        "  #hidden_dim: output of RNN (1-1, m-1, m-m)\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.embedding_layer = nn.Embedding(input_dim, embedding_dim) #put one-hot input in encoder to get embedding\n",
        "    self.rnn_cell = nn.RNN(embedding_dim, hidden_dim) #get rnn\n",
        "    self.fc_layer = nn.Linear(hidden_dim, output_dim) #get output\n",
        "      \n",
        "  def forward(self, text):\n",
        "    \"\"\"\n",
        "    Foward pass\n",
        "    Args:\n",
        "        text: (movie review, represented as one-hot-encoding)\n",
        "            sentiment text with shape [sentence length, batch size]\n",
        "    \"\"\"\n",
        "    embedded = self.embedding_layer(text) # embedding_layer output shape  (sentence length, batch size, embedding dim]\n",
        "    output, hidden = self.rnn_cell(embedded) # output and hidden state (they should be equal hidden = output)\n",
        "    \n",
        "    assert torch.equal(output[-1,:,:], hidden.squeeze(0)) \n",
        "    \n",
        "    return self.fc_layer(hidden.squeeze(0)) #output = vector of output_dim length."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5G_zCcUYcA0"
      },
      "source": [
        "input_dim = len(TEXT.vocab) #input dimension is the dimension of the one-hot vectors\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256 #size of the hidden states (a tensor)\n",
        "output_dim = 1 # for the fully connected (one neuron at the end, we use sigmoid)\n",
        "\n",
        "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8mzk7joYcA1"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSjst1pIYcA2"
      },
      "source": [
        "import torch.optim as optim\n",
        "# define loss function and optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#make model instance and send it to training device\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gfwn1NiYcA3"
      },
      "source": [
        "# DONE: Implement accuracy_calculator which takes predicted labels and real labels\n",
        "\n",
        "def accuracy_calculator(preds, y):\n",
        "  \"\"\"Returns accuracy per batch\"\"\" \n",
        "\n",
        "  preds = torch.sigmoid(preds)    # Apply sigmoid after fc from model\n",
        "  preds = torch.round(preds)      # round elements to 0 or 1 in tensor\n",
        "  TruePositives_batch = sum(preds == y) #true positives\n",
        "  accuracy = TruePositives_batch/float(len(preds))\n",
        "  return accuracy"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVcX-RZiYcA4"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  for batch in iterator:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1) #size [batch_size=64, 1]  => [batch_size=64]\n",
        "    \n",
        "    loss = criterion(predictions, batch.label)\n",
        "\n",
        "    acc = accuracy_calculator(predictions, batch.label)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "      \n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJQQ4_lxYcA4"
      },
      "source": [
        "def evaluate_model(model, data_batches, criterion):\n",
        "  eval_loss = 0\n",
        "  eval_acc = 0\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for batch in data_batches:\n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      \n",
        "      acc = accuracy_calculator(predictions, batch.label)\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += acc.item()\n",
        "  \n",
        "  return eval_loss / len(data_batches), eval_acc / len(data_batches)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4h83ON-Yae2",
        "outputId": "dc13c105-7603-4c07-be3d-1b2ac7a61d6e"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate_model(model, valid_iterator, criterion)\n",
        "  \n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'best-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1} , Train [Loss:  {train_loss:.3f}  Acc :{train_acc*100:.2f}], Val.[Loss: {valid_loss:.3f} Acc: {valid_acc*100:.2f}]')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 , Train [Loss:  0.694  Acc :50.03], Val.[Loss: 0.696 Acc: 50.08]\n",
            "Epoch: 2 , Train [Loss:  0.693  Acc :49.91], Val.[Loss: 0.696 Acc: 50.04]\n",
            "Epoch: 4 , Train [Loss:  0.693  Acc :49.84], Val.[Loss: 0.696 Acc: 49.96]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPqbylW4zRCz"
      },
      "source": [
        "## Save and load model for Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1lECvJOYcA6",
        "outputId": "7e685c22-9377-4e23-8cb5-36f2d3947d32"
      },
      "source": [
        "model.load_state_dict(torch.load('best-model.pt')) #Load the best model\n",
        "test_loss, test_acc = evaluate_model(model, test_iterator, criterion)\n",
        "print(f'Accuracy on test data : {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data : 47.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMeZxj-wCwqg"
      },
      "source": [
        "## More on Tensorflow and Keras\n",
        "```\n",
        "1. Data Preprocessing\n",
        "2. Simple Neural Network\n",
        "3. Convolutional Neural Network\n",
        "4. Recurrent Neural Network \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWqBtEhnDIyF"
      },
      "source": [
        "## Download, unzip and read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "6WcXyrYUAFnf",
        "outputId": "a12948f3-0e27-4c87-ab66-8048b8114f48"
      },
      "source": [
        "!pip install wget\n",
        "\n",
        "import pandas as pd\n",
        "import wget, zipfile\n",
        "\n",
        "wget.download('https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv')\n",
        "# !wget https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\n",
        "\n",
        "movie_reviews = pd.read_csv(\"IMDb_Reviews.csv\")\n",
        "movie_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My family and I normally do not watch local mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Believe it or not, this was at one time the wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After some internet surfing, I found the \"Home...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of the most unheralded great works of anim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  My family and I normally do not watch local mo...          1\n",
              "1  Believe it or not, this was at one time the wo...          0\n",
              "2  After some internet surfing, I found the \"Home...          0\n",
              "3  One of the most unheralded great works of anim...          1\n",
              "4  It was the Sixties, and anyone with long hair ...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "5Qn2raI4BZhM",
        "outputId": "9cbc33c9-3d32-4d99-9951-59cba37cfc4a"
      },
      "source": [
        "# DONE: See Visualize class distribution (balanced or not). i.e use matplotlib or plotly\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "print(movie_reviews[\"review\"][3],'\\n')\n",
        "print(movie_reviews.sentiment.value_counts(),'\\n')\n",
        "\n",
        "movie_reviews.sentiment.value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One of the most unheralded great works of animation. Though it makes the most sophisticated use of the \"cut-out\" method of animation (a la \"South Park\"), the real talent behind \"Twice Upon a Time\" are the vocal characterizations, with Lorenzo Music's (Carlton from TV's \"Rhoda\") Woody Allen-ish Ralph-the-all-purpose-Animal being the centerpiece. The \"accidental nightmare\" sequence is doubtless one of the best pieces of animation ever filmed. \n",
            "\n",
            "1    25000\n",
            "0    25000\n",
            "Name: sentiment, dtype: int64 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9927ea3d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jxwk0qtECL6"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcT1l3dZEWyR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, Conv1D, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfSiEcT1EAMh"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "  # Removing tags\n",
        "  sentence = remove_tags(sen)\n",
        "\n",
        "  # Remove punctuations and numbers\n",
        "  sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "  return sentence\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "  return TAG_RE.sub('', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-eSbNgPENDT"
      },
      "source": [
        "# Clean the data\n",
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "  X.append(preprocess_text(sen))\n",
        "\n",
        "#Split the data to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, movie_reviews['sentiment'].values, test_size=0.20, random_state=42)\n",
        "\n",
        "#Tokenize the data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ztmHSn60yi",
        "outputId": "6b7216d9-fef4-4e0c-f2b2-45f828525778"
      },
      "source": [
        "X_train[1].T #vector of word representations "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  70, 1688,    2,  608,   17,  226,   58,   72,   48,   17,   72,\n",
              "        928,   32,  364,    3,  475,  588,    1,  362,    2,  283,    1,\n",
              "         12,  171,   96,  191,   53,   27,   84,   10, 1091,   89,  651,\n",
              "        521,   39,   83,   69,  425,    8,   12,   48,   10,  537,    2,\n",
              "       3808,  146, 1118,    1,  546,  288,   11,   77,   11, 1955,    1,\n",
              "        110,    5,  179,   70,    1,  765,    5,  179,   70,    1,  608,\n",
              "       1163,  154, 1492,   15,    1,  352,   66,  128,  179,  410,  135,\n",
              "       2049,   51,   55,  151,    1,   12,  546,   42, 1183,   13,   64,\n",
              "        128,   97,    6,  271,  393,   13,    1,   45,  156,  206,   17,\n",
              "        115], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PozGpmBQE7W7"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67fKH7Qpuv1",
        "outputId": "b34b3ee6-be43-4716-e09b-bb8f6e2c5150"
      },
      "source": [
        "X_train[1] #vector of word representations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  70, 1688,    2,  608,   17,  226,   58,   72,   48,   17,   72,\n",
              "        928,   32,  364,    3,  475,  588,    1,  362,    2,  283,    1,\n",
              "         12,  171,   96,  191,   53,   27,   84,   10, 1091,   89,  651,\n",
              "        521,   39,   83,   69,  425,    8,   12,   48,   10,  537,    2,\n",
              "       3808,  146, 1118,    1,  546,  288,   11,   77,   11, 1955,    1,\n",
              "        110,    5,  179,   70,    1,  765,    5,  179,   70,    1,  608,\n",
              "       1163,  154, 1492,   15,    1,  352,   66,  128,  179,  410,  135,\n",
              "       2049,   51,   55,  151,    1,   12,  546,   42, 1183,   13,   64,\n",
              "        128,   97,    6,  271,  393,   13,    1,   45,  156,  206,   17,\n",
              "        115], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKRG1QCyFFdo"
      },
      "source": [
        "### Get pre-trained embeddings (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJwySSAyIxw0"
      },
      "source": [
        "# DONE : Download Glove embeddings from http://nlp.stanford.edu/data/glove.6B.zip and unzip.\n",
        "import requests \n",
        "\n",
        "#function copied from: https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url/51292933\n",
        "def download_url(url, save_path, chunk_size=128):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            fd.write(chunk)\n",
        "\n",
        "path = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "save_path = 'save_path.zip'\n",
        "download_url(path, save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-HQa_2ciWoY"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(save_path, 'r') as zipObj:\n",
        "  zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbvBbVKXFMMf"
      },
      "source": [
        "# Retrieve the embeddings and embedding matrix \n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in glove_file:\n",
        "  records = line.split()\n",
        "  word = records[0]\n",
        "  vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "  embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100)) # each embedding is of size 100 (maxlen) (100 columns)\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  embedding_vector = embeddings_dictionary.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a9loV9D9Ng9",
        "outputId": "f542e7b8-b353-4ccc-f495-27646287d0cf"
      },
      "source": [
        "print(embedding_matrix.shape) #92303 words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(92303, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEELt92qFf1d"
      },
      "source": [
        "### Simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM4GbiQ3Fkbt",
        "outputId": "f3743c58-1460-4bef-bf80-209dfd94f636"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Create, add Embedding layer and freeze it \n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "#Flatten the embedding output \n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Specify the optimizer, loss function and metric \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          9230300   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                640064    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 9,872,717\n",
            "Trainable params: 642,417\n",
            "Non-trainable params: 9,230,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rdrmKl-F50Z",
        "outputId": "a7eddc06-7d20-401b-8d12-3cc0cad66941"
      },
      "source": [
        "# Train the model by calling the fit method. Specify the batch size, number of epochs and validation (optional)\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=0, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.0359 - acc: 0.7142\n",
            "Test Score: 1.0358617305755615\n",
            "Test Accuracy: 0.7142000198364258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E0FPWiLF_5I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "05f4b6c4-7de5-4f27-e542-ddd9bf7ddde6"
      },
      "source": [
        "# #DONE: Visualize the accuracy and loss of the model using i.e matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['loss']\n",
        "acc_train = history.history['acc']\n",
        "\n",
        "loss_val = history.history['val_loss']\n",
        "acc_val = history.history['val_acc']\n",
        "\n",
        "plt_epochs = range(1,11)\n",
        "\n",
        "plt.plot(plt_epochs, loss_train)\n",
        "plt.plot(plt_epochs, acc_train)\n",
        "plt.plot(plt_epochs, loss_val)\n",
        "plt.plot(plt_epochs, acc_val)\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss and Training Accuracy')\n",
        "plt.legend([\"train loss\",\"train accuracy\",\"validation loss\",\"validation accuracy\"], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ktYL-UGRtw"
      },
      "source": [
        "### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcs3L2c2GRIi",
        "outputId": "e3108623-68b6-4d97-cd27-475577ef3711"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          9230300   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 9,294,557\n",
            "Trainable params: 64,257\n",
            "Non-trainable params: 9,230,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgsjjHTYG_wv",
        "outputId": "edffded0-9a70-41f2-9775-7056a38b6c9e"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=0, validation_split=0.2)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3587 - acc: 0.8419\n",
            "Test Score: 0.35869643092155457\n",
            "Test Accuracy: 0.8418999910354614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPPrL-YNHlMb"
      },
      "source": [
        "### Recurrent Neural Network (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8y0812vN2RH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed20654-0552-42ef-f1a7-c2adcc6754d8"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import random\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT2 = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')#, include_lengths=True)\n",
        "LABEL2 = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_data2, test_data2 = datasets.IMDB.splits(TEXT2, LABEL2)\n",
        "train_data2, valid_data2 = train_data2.split(random_state = random.seed(SEED))\n",
        "\n",
        "\n",
        "TEXT2.build_vocab(train_data2, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\")\n",
        "LABEL2.build_vocab(train_data2)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data2, valid_data2, test_data2), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|| 84.1M/84.1M [00:07<00:00, 11.1MB/s]\n",
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.27MB/s]                           \n",
            "100%|| 398074/400000 [00:22<00:00, 18162.28it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inLKlHMHHD56"
      },
      "source": [
        "# 1. Make improvements of the current RNN\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  #input_dim: dim of one hot encoding\n",
        "  #hidden_dim: output of RNN (1-1, m-1, m-m)\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.embedding_layer = nn.Embedding(input_dim, embedding_dim) #put one-hot input in encoder to get embedding\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim) #get rnn\n",
        "    self.fc_layer = nn.Linear(hidden_dim, output_dim) #get output\n",
        "      \n",
        "  def forward(self, text):#, text_lengths):\n",
        "    \"\"\"\n",
        "    Foward pass\n",
        "    Args:\n",
        "        text: (movie review, represented as one-hot-encoding)\n",
        "            sentiment text with shape [sentence length, batch size]\n",
        "    \"\"\"\n",
        "    embedded = self.embedding_layer(text) # embedding_layer output shape  (sentence length, batch size, embedding dim]\n",
        "    # packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu')) #PACK sequence\n",
        "    output, (hidden, cell) = self.lstm(embedded)\n",
        "    # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output) #UNPACK sequence\n",
        "        \n",
        "    return self.fc_layer(hidden.squeeze(0)) #output = vector of output_dim length."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a39Mbd0EBuIL"
      },
      "source": [
        "input_dim = len(TEXT2.vocab) #input dimension is the dimension of the one-hot vectors\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256 #size of the hidden states (a tensor)\n",
        "output_dim = 1 # for the fully connected (one neuron at the end, we use sigmoid)\n",
        "\n",
        "model2 = LSTM(input_dim, embedding_dim, hidden_dim, output_dim)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfvJq_gdW8b6",
        "outputId": "573d4cd0-ec31-4b87-976b-5ba7528f64d9"
      },
      "source": [
        "#replace initial weights with pretrained weights (embeddings)\n",
        "pretrained_embeddings = TEXT2.vocab.vectors\n",
        "model2.embedding_layer.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbf4aUvHkeSS"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  for batch in iterator:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    batch_texts = batch.text\n",
        "    predictions = model(batch_texts).squeeze(1) #size [batch_size=64, 1]  => [batch_size=64]\n",
        "    \n",
        "    loss = criterion(predictions, batch.label)\n",
        "\n",
        "    acc = accuracy_calculator(predictions, batch.label)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "      \n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzN3SmJBK713",
        "outputId": "02f84c5c-7044-46aa-d986-a2873194e7ff"
      },
      "source": [
        "import torch.optim as optim\n",
        "# define loss function and optimizer\n",
        "optimizer = optim.Adam(model2.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#make model instance and send it to training device\n",
        "model2 = model2.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model2, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate_model(model2, valid_iterator, criterion)\n",
        "  \n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model2.state_dict(), 'best-model-lstm.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1} , Train [Loss:  {train_loss:.3f}  Acc :{train_acc*100:.2f}], Val.[Loss: {valid_loss:.3f} Acc: {valid_acc*100:.2f}]')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 , Train [Loss:  0.694  Acc :49.98], Val.[Loss: 0.693 Acc: 49.42]\n",
            "Epoch: 3 , Train [Loss:  0.694  Acc :50.24], Val.[Loss: 0.693 Acc: 50.49]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsxcnRVWXsvk",
        "outputId": "31904dbb-f920-4551-fb16-7306eccbc137"
      },
      "source": [
        "# 2. Calculate number of model parameters (traninable and non-trainable)\n",
        "trainables = sum(p.numel() for p in model2.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters:\", trainables)\n",
        "\n",
        "nontrainables = sum(p.numel() for p in model2.parameters() if not p.requires_grad)\n",
        "print(\"Number of non-trainable parameters:\", nontrainables)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 2867049\n",
            "Number of non-trainable parameters: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "044LEgZibxwL"
      },
      "source": [
        "#Method #2: Keras\n",
        "#lab 4: \"lstm then try gru then try rnn\" Gcniziwe\n",
        "model2k = Sequential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1cwiHTLlwGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef531f5-df3b-449f-c189-a31afdc8e8f0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnBj1U6DjcAw",
        "outputId": "bcf9134a-a37b-445f-b384-e9b6157fd79a"
      },
      "source": [
        "# 3. Implement a method that will take a string (review sentence) and return a sentiment of that string\n",
        "from collections import Counter\n",
        "\n",
        "def sentence_sentiment(string, threshold):\n",
        "  sentence = preprocess_text(string)\n",
        "  sentence = [sentence]\n",
        "  sentence = tokenizer.texts_to_sequences(sentence) #[[int],[int]...]\n",
        "  sentence = pad_sequences(sentence, padding='post', maxlen=maxlen)\n",
        "  \n",
        "  sentiment = model.predict(sentence)\n",
        "\n",
        "  return \"pos\" if (sentiment >= threshold) else \"neg\"\n",
        "\n",
        "\n",
        "sentences = movie_reviews['review']\n",
        "sentiments = movie_reviews['sentiment']\n",
        "threshold = 0.5\n",
        "\n",
        "for i, sen in enumerate(sentences):\n",
        "  if(i<5):\n",
        "    result = sentence_sentiment(sen, threshold)\n",
        "    print(\"sentiment\", result)\n",
        "    print(\"expected:\", sentiments[i], '\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment pos\n",
            "expected: 1 \n",
            "\n",
            "sentiment neg\n",
            "expected: 0 \n",
            "\n",
            "sentiment neg\n",
            "expected: 0 \n",
            "\n",
            "sentiment pos\n",
            "expected: 1 \n",
            "\n",
            "sentiment pos\n",
            "expected: 0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uK0GklzYcA6"
      },
      "source": [
        "## Lab Task\n",
        "```\n",
        "1. Make improvements of the current RNN by : \n",
        "  - Usin pre-trained word embeddings (GloVe)\n",
        "  - different RNN architecture\n",
        "  - multi-layer RNN or LSTM\n",
        "  - a different optimizer\n",
        "2. Calculate number of model parameters (traninable and non-trainable)\n",
        "3. Implement a method that will take a string (review sentence) and return a sentiment of that string\n",
        "\n",
        "**Try to get accuracy > 80%\n",
        "```\n",
        "\n",
        "<b>Note: </b> [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/) <br>\n",
        "<center>Don't to forget to make a Git commit</center>"
      ]
    }
  ]
}